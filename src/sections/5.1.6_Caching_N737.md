The code incorporates a cache implemented with the Ristretto library [@ristretto]. The cache size can be determined according to needs, but it is found that sizes exceeding 1GB perform quite satisfactorily. In this implementation, a 3GB size is chosen, as this is the amount of spare memory available. This memory remains in use and is only evicted or subjected to garbage collection when new requests are made.

Estimating the true memory footprint of complex data structures can be challenging in many programming languages, especially when they involve pointers. These pointers typically reference the location of data rather than the data itself, leading to potential underestimations of actual memory usage. In the context of the Go application, a specified cost per item stored in the cache is required. To address this, the size of one Candle struct is determined to be 65 bytes. Multiplying this by 5000 gives the estimated size for a set of candles. Adding some buffer for additional overhead and metadata, a rounded value of 360,512 bytes is determined. This suggests that the cache can accommodate approximately 8000 such items.

Since historical data remains static, it can be safely stored in cache without any timeout. However, there are instances where incomplete candle blocks are stored. To account for potential real-time use of the algorithm, a time-to-live is added to incomplete blocks. Given that algorithms typically complete in a few seconds, the time-to-live is set to 10 seconds. If dealing with second-level data, the time-to-live could theoretically be reduced to as low as one second.

From an algorithm's perspective, all data is cached. Once the service receives an initial request, all subsequent requests receive immediate responses. This functionality enables near real-time previews of indicators and algorithm results by minimizing the overhead of calculating transition and intermediate blocks for each request.