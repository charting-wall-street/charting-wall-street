The initial concept of dividing the dataset into blocks was inspired by the common practice of chunked data requests over HTTP, aiming to optimize both storage and retrieval processes. By partitioning data into blocks, it aligns with the typical nature of web requests, where data is fetched or sent in batches rather than as continuous streams. Consequently, creating blocks consisting of 5,000 candles not only streamlines the storage and retrieval processes but also results in a more manageable payload size. This smaller, block-sized payload can then be efficiently sent over HTTP to the web client, allowing for smoother rendering of each candle on a canvas.

The expansion to include indicators not only leverages the existing candle drawing logic but also the block-based data structuring. When we structure the indicators using consistent blocks of 5,000 candles with the same time offset, we gain the advantage of flexibility in interval scaling. Essentially, if each block represents a 1-minute interval, combining five such blocks gives a 5-minute interval, and further merging results in extended intervals like 10 minutes, 30 minutes, and so forth. This block merging approach offers a systematic method for scaling, but it comes with a limitation: it does not perfectly align with natural time divisions like months or years, as these are not strictly based on fixed-length periods.

While the block merging approach offers systematic flexibility, using Unix timestamps as the starting point introduces its own set of complexities. Data predating the Unix epoch can result in negative timestamps. When these timestamps are divided by the number of candles to determine the block index, any value between -1 and 0 gets rounded to 0, courtesy of integer division logic. This rounding forces us to implement extra checks. A potential remedy might be to introduce a large offset to the Unix timestamp. Though such a deviation from standard practice might not be conventional, its utility is evident and may merit exploration in future iterations or platform reworks.

In the endeavor to maintain consistency across all Go projects, we established distinct packages specifically for containers related to candles and indicators. This structure not only ensures easy access to universal utility functions across services but also refines the operational flow. With this, both candle and indicator blocks can seamlessly represent data from diverse assets. We've incorporated serialization functions directly into the package, enhancing the efficiency of data storage and retrieval, whether from local storage or over the network. For data types, we followed conventions outlined in both the Binance API and EOD API, which employ $float64$ types for most fields, except for timestamps and indices. This adherence simplifies the data integration process, ensuring compatibility and coherence with established data formats.

The adoption of candle blocks significantly enhances the speed of calculating indicators and working with candle data. By eliminating this bottleneck and standardizing the structure in the pipeline, we can concentrate on the actual processing of the data.