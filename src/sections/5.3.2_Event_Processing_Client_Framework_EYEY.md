
In order to make it possible to easily run, and work on different algorithms, we implemented a package that is used as the backbone for a running script. We will refer to this package as "algocore". Besides including all the logic to run scripts, it also includes all types that are used to reply to requests. With this, we can add this as a dependency to the event processor, and easily decode any replies.

Go refers to dependencies as modules, and each module can include any number of packages. In the case, the algocore package contains a few useful packages:

 - algo: Contains a set of structs to contain the results of an algorithms output.
 - env: Contains all interfaces and helper functions used to provide all interfaces needed for a script.
 - kiosk: Provides an interface to retrieve data from any of the daemons.
 - ritmic: Contains the web server logic, used to launch the script when running headless.

**kiosk**

The key components in this module is the kiosk package. As this package is responsible for providing access to all the services, and returning them in the appropriate structure, it contains functions to access any candle blocks, indicator blocks, and algorithm events. It also provides an extra flag to retrieve the transition variant for any block.

When building the kiosk package, we started from the existing work that was done in the indicator processor, and reused a lot of the logic that was already implemented there. We did repackage them in order to make them more reusable. In order to make it easy for any service that might need to retrieve data from the pipeline, we created a series of data supplier structs. The data suppliers provide a robust interface that uses all the caching logic that was discussed in 5.2.5 to reduce the number of outgoing requests. Since indicators were only able to retrieve and cache candle blocks, the logic has been expanded to include indicator blocks and algorithm events.

As a reminder, the caching logic in 5.2.5 aims to minimize outgoing requests and reduce data retrieval response time. We achieve this by caching previously fetched data like candle blocks, indicator blocks, and algorithm events. This caching mechanism speeds up the access to frequently queried data, eliminating redundant requests and thus cutting down overhead.

The supplier logic is structured as:

```
INTERFACE MarketSupplier
    METHOD Algorithm(name: string, params: array of float64) RETURNS AlgorithmSupplier
    METHOD Interval(interval: integer) RETURNS IntervalSupplier
    METHOD Price() RETURNS float64
    METHOD Time() RETURNS integer

INTERFACE IntervalSupplier
    METHOD Candle() RETURNS Candle
    METHOD FromLast(offset: integer) RETURNS Candle
    METHOD ToTimeStamp(index: integer) RETURNS integer
    METHOD ToIndex(timeStamp: integer) RETURNS integer
    METHOD Indicator(name: string, params: array of integer) RETURNS IndicatorSupplier

INTERFACE IndicatorSupplier
    METHOD Value() RETURNS float64
    METHOD Exists() RETURNS boolean
    METHOD Series(key: string) RETURNS float64

INTERFACE AlgorithmSupplier
    METHOD Events() RETURNS array of Event
    METHOD PastEvents() RETURNS array of Event
    METHOD LastEvents() RETURNS array of Event
    METHOD HasEvents() RETURNS boolean
```

This structure facilitates requests for any candle, indicator, and computed algorithms.

<!-- Insert a figure here showing the hierarchy? -->

We earlier mentioned that caching is done in each service, with the goal of being able to simply request any data, and not having to worry about introducing too much overhead. For cases where the suppliers are overkill, or cases that do not work on a block basis, e.g., the validation scripts, we provide an alternative. We provide getter functions to access data for any service. These getters will execute the http request, and return it in the correct type. On top of that, since we have designed a encoding for blocks to binary, we can make sure that the transfer is done as efficiently as possible.

With the kiosk package we can not effectively feed any data that we need to the scripts. On top of that, this is also the way that we retrieve data for the evaluation scripts, as those are also written in Go, the final payoff was that we did not have to write any logic for logistics in retrieving data.

**env**

The environment package contains all the suppliers that we mentioned before. On top of that we also provide an interface for the memory and parameters. This way these interfaces could be reused tot potentially expand the algorithm logic to other purposes like strategy evaluation.

The memory and parameters interfaces are essential components of the env package, as they allow for more structured and controlled access to the script's state and input parameters. The memory interface makes it easy to store and retrieve the script's state, while the parameters' interface ensures that input parameters are accessed and parsed without the need for error handling.

The parameters are defined in advance, and can thus be retrieved by their key. If a parameter is missing, then this will make the program crash. This avoids any accidental parameter usages that were not intended with the use of indices, and also makes it convenient to retrieve parameters in the correct type.

Given that the scripts maintain a state, there's a necessity for a storage mechanism for this state. In the design, we've adopted a simple approach: the script is permitted to store any struct it desires. This stored struct can be retrieved in subsequent steps, and its type can be defined by the script. If there's a need for the script to update the state, it has two options. It can either push the modified struct back into memory or utilize a pointer to the struct, ensuring updates are reflected directly in the stored data.

The pseudocode representation of the storage mechanism:

```
INTERFACE Parameters
    METHOD Get(key: string) RETURNS float64
    METHOD GetInt(key: string) RETURNS integer

INTERFACE Memory
    METHOD Store(data: any type)
    METHOD Read() RETURNS any type

```

Through this structure, we empower scripts with the flexibility to manage their state seamlessly, be it reading, storing, or updating.

**ritmic**

The actual running of the scripts happens with the ritmic package. This package simply accepts the step function for the algorithm, and sets up the server which is on stand-by for any simulation requests. Since debugging is hard once the script is running in the daemonized environment, we also provide testing function, in order to evaluate the stepping function without the need to start a server.

When talking about a set of parameters, we refer to this set as a scenario. The ritmic server is able to evaluate multiple scenarios in parallel, but sequentially evaluates each scenario to avoid any data leakage. The evaluation of scripts goes as follows:

1. Create a provider for all scenarios using the kiosk's Provider factory, provided the symbol and resolution as input.
2. Iterates through each block of candle data.
3. For each block, retrieve the current and previous block using the data provider that we created earlier.
4. Iterates through 5000 candles, skipping the ones with missing data.
5. Create a MarketSupplier for the current time instance using both blocks.
6. Iterates through all the scenarios and for each scenario:
7. Retrieve the memory associated with the scenario.
8. Creates a result handler for storing the results.
9. Evaluate the trading script using the stepper function

The primary method for storing results in the design is the use of nested maps. This implementation detail remains concealed from the script. Instead, the script interacts with the provided interface, thereby allowing optimizations in the result-gathering process and mitigating potential issues like unintentional cheating if a structure were to be passed to the step function directly.

The pseudocode representation:

```
INTERFACE ResultSet
    METHOD GetSymbolResultSet(symbol: string) RETURNS SymbolResultSet

INTERFACE SymbolResultSet
    METHOD GetScenarioSet(index: integer) RETURNS ScenarioSet

INTERFACE ScenarioSet
    METHOD GetEvent(index: integer) RETURNS Event
    METHOD GetParameters() RETURNS list of float64

INTERFACE Event
    METHOD AddSegment(segment: SegmentAnnotation) RETURNS Event
    METHOD AddPoint(point: PointAnnotation) RETURNS Event
    METHOD AddEvent(event: Event, label: string) RETURNS Event
    METHOD SetColor(color: string) RETURNS Event
    METHOD SetIcon(icon: string) RETURNS Event
    METHOD SetPrice(price: float64) RETURNS Event
    METHOD SetTime(ts: integer) RETURNS Event

INTERFACE ResultHandler (available for the step function)
    METHOD NewEvent(label: string) RETURNS Event
```

Once the results are compiled, the system encodes them in JSON format and sends it back to the requester. In case of execution errors, the web server will attempt to catch and return the error. However, for grave errors, such as trying to access negative time indices, the program will terminate abruptly, since such scenarios should never transpire.

In summary, the algocore package serves as the payoff of the preprocessing work. It gives a simple interface to all data related to technical analysis. By having caching at every step in the pipeline it makes it possible to have extremely fast replies, and thus finally possible to evaluate multiple scenarios which would never be as quick using online services, or simple databases.

The evaluation process in the ritmic package is structured to ensure efficient execution of the algorithm scripts. By evaluating multiple scenarios in parallel and sequentially evaluating each scenario, the process minimizes the potential for data leakage and ensures that each scenario is evaluated independently. By taking these precautions in advance, we can say with confidence that chances of accidental leakages are second to none. This structure also allows for a more organized flow of data, as these parallel requests have a better chances of generating cache hits.